{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9du08Idnwy9g"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "dev = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "y-KPQyF9Oyt9"
   },
   "outputs": [],
   "source": [
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "    \n",
    "    __str__ = __repr__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "3PDGhDo0yFjS"
   },
   "outputs": [],
   "source": [
    "std_transform = Compose([\n",
    "  ToTensor(),\n",
    "  Normalize((0.1307), (0.3081)), # mean and standard deviation\n",
    "  AddGaussianNoise(0., 0.6),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lLCNO2MHxoCX"
   },
   "outputs": [],
   "source": [
    "train_ds = MNIST(root='downloads', train=True, download=True, transform = std_transform)\n",
    "valid_ds = MNIST(root='downloads', train=False, download=True, transform = std_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "E_viXBi1yOc4"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size=512, shuffle = True, drop_last = True)\n",
    "valid_loader = DataLoader(valid_ds, batch_size=512, shuffle = True, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "Vcub2ssJyUDY",
    "outputId": "7f7eac81-32f7-46b2-e9ed-6c009205a713"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truth: tensor(5)\n",
      "tensor(-2.9933)\n"
     ]
    }
   ],
   "source": [
    "def print_imgs(model=None):\n",
    "    if (model):\n",
    "      plt.imshow(model(torch.randn(512, 128).to(dev).cpu().detach()[0,0], cmap='gray'))\n",
    "    else:\n",
    "      data, label = next(iter(train_loader))\n",
    "      print(\"Truth:\", label[0])\n",
    "      plt.imshow(data[0,0], cmap='gray')\n",
    "print_imgs()\n",
    "data, label = next(iter(train_loader))\n",
    "print(torch.min(data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "z3owxpzHPpD3"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(28 * 28, 50),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(50, 50),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(50, 10),\n",
    "        nn.Softmax(dim=1),\n",
    "    )\n",
    "  def forward(self, x):\n",
    "    x = self.layers(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xP7P5kLYQlyT"
   },
   "outputs": [],
   "source": [
    "model = Net().to(dev)\n",
    "optim = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "cross_entropy = torch.nn.CrossEntropyLoss().to(dev)\n",
    "\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jOKQNriuTs6U"
   },
   "outputs": [],
   "source": [
    "def test(model, test_loader, cross_entropy):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(dev), target.to(dev)\n",
    "            output = model(data)\n",
    "            predict = cross_entropy(output.log(), target)\n",
    "            test_loss += predict.item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "collapsed": true,
    "id": "tm-gutXASvGd",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "36654f94-4b0e-42fc-fd7d-16433b1d84a0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.0043, Accuracy: 1498/10000 (15%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 2256/10000 (23%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 2376/10000 (24%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 2733/10000 (27%)\n",
      "Test set: Average loss: 0.0035, Accuracy: 3928/10000 (39%)\n",
      "Test set: Average loss: 0.0033, Accuracy: 5157/10000 (52%)\n",
      "Test set: Average loss: 0.0035, Accuracy: 5324/10000 (53%)\n",
      "Test set: Average loss: 0.0035, Accuracy: 5383/10000 (54%)\n",
      "Test set: Average loss: 0.0032, Accuracy: 6015/10000 (60%)\n",
      "Test set: Average loss: 0.0032, Accuracy: 6855/10000 (69%)\n",
      "Test set: Average loss: 0.0032, Accuracy: 6979/10000 (70%)\n",
      "Test set: Average loss: 0.0028, Accuracy: 7142/10000 (71%)\n",
      "Test set: Average loss: 0.0026, Accuracy: 7657/10000 (77%)\n",
      "Test set: Average loss: 0.0027, Accuracy: 7796/10000 (78%)\n",
      "Test set: Average loss: 0.0027, Accuracy: 7896/10000 (79%)\n",
      "Test set: Average loss: 0.0028, Accuracy: 7966/10000 (80%)\n",
      "Test set: Average loss: 0.0028, Accuracy: 7998/10000 (80%)\n",
      "Test set: Average loss: 0.0029, Accuracy: 8035/10000 (80%)\n",
      "Test set: Average loss: 0.0029, Accuracy: 8033/10000 (80%)\n",
      "Test set: Average loss: 0.0030, Accuracy: 8093/10000 (81%)\n",
      "Test set: Average loss: 0.0030, Accuracy: 8099/10000 (81%)\n",
      "Test set: Average loss: 0.0031, Accuracy: 8105/10000 (81%)\n",
      "Test set: Average loss: 0.0031, Accuracy: 8130/10000 (81%)\n",
      "Test set: Average loss: 0.0031, Accuracy: 8121/10000 (81%)\n",
      "Test set: Average loss: 0.0031, Accuracy: 8138/10000 (81%)\n",
      "Test set: Average loss: 0.0032, Accuracy: 8119/10000 (81%)\n",
      "Test set: Average loss: 0.0032, Accuracy: 8176/10000 (82%)\n",
      "Test set: Average loss: 0.0033, Accuracy: 8162/10000 (82%)\n",
      "Test set: Average loss: 0.0033, Accuracy: 8153/10000 (82%)\n",
      "Test set: Average loss: 0.0033, Accuracy: 8172/10000 (82%)\n",
      "Test set: Average loss: 0.0033, Accuracy: 8177/10000 (82%)\n",
      "Test set: Average loss: 0.0034, Accuracy: 8195/10000 (82%)\n",
      "Test set: Average loss: 0.0034, Accuracy: 8181/10000 (82%)\n",
      "Test set: Average loss: 0.0034, Accuracy: 8202/10000 (82%)\n",
      "Test set: Average loss: 0.0034, Accuracy: 8208/10000 (82%)\n",
      "Test set: Average loss: 0.0034, Accuracy: 8222/10000 (82%)\n",
      "Test set: Average loss: 0.0034, Accuracy: 8202/10000 (82%)\n",
      "Test set: Average loss: 0.0035, Accuracy: 8219/10000 (82%)\n",
      "Test set: Average loss: 0.0035, Accuracy: 8213/10000 (82%)\n",
      "Test set: Average loss: 0.0035, Accuracy: 8208/10000 (82%)\n",
      "Test set: Average loss: 0.0035, Accuracy: 8243/10000 (82%)\n",
      "Test set: Average loss: 0.0036, Accuracy: 8234/10000 (82%)\n",
      "Test set: Average loss: 0.0036, Accuracy: 8217/10000 (82%)\n",
      "Test set: Average loss: 0.0036, Accuracy: 8221/10000 (82%)\n",
      "Test set: Average loss: 0.0036, Accuracy: 8207/10000 (82%)\n",
      "Test set: Average loss: 0.0037, Accuracy: 8234/10000 (82%)\n",
      "Test set: Average loss: 0.0036, Accuracy: 8267/10000 (83%)\n",
      "Test set: Average loss: 0.0036, Accuracy: 8268/10000 (83%)\n",
      "Test set: Average loss: 0.0036, Accuracy: 8242/10000 (82%)\n",
      "Test set: Average loss: 0.0037, Accuracy: 8257/10000 (83%)\n",
      "Test set: Average loss: 0.0037, Accuracy: 8274/10000 (83%)\n",
      "Test set: Average loss: 0.0037, Accuracy: 8250/10000 (82%)\n",
      "Test set: Average loss: 0.0037, Accuracy: 8256/10000 (83%)\n",
      "Test set: Average loss: 0.0037, Accuracy: 8279/10000 (83%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8235/10000 (82%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8255/10000 (83%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8264/10000 (83%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8268/10000 (83%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8279/10000 (83%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8282/10000 (83%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8275/10000 (83%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8311/10000 (83%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8287/10000 (83%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8277/10000 (83%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8249/10000 (82%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8280/10000 (83%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8284/10000 (83%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8269/10000 (83%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8288/10000 (83%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8269/10000 (83%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8306/10000 (83%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8295/10000 (83%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8304/10000 (83%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8310/10000 (83%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8314/10000 (83%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8319/10000 (83%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8305/10000 (83%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8330/10000 (83%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8303/10000 (83%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8297/10000 (83%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8300/10000 (83%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8308/10000 (83%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8309/10000 (83%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8326/10000 (83%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8304/10000 (83%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8323/10000 (83%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8310/10000 (83%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8324/10000 (83%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8315/10000 (83%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8314/10000 (83%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8343/10000 (83%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8330/10000 (83%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8325/10000 (83%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8335/10000 (83%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8321/10000 (83%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8314/10000 (83%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8353/10000 (84%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8316/10000 (83%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8324/10000 (83%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8331/10000 (83%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8347/10000 (83%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8310/10000 (83%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8334/10000 (83%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8348/10000 (83%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8322/10000 (83%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8327/10000 (83%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8327/10000 (83%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8363/10000 (84%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8333/10000 (83%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8354/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8358/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8335/10000 (83%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8356/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8350/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8347/10000 (83%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8352/10000 (84%)\n",
      "Test set: Average loss: 0.0043, Accuracy: 8333/10000 (83%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8342/10000 (83%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8331/10000 (83%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8345/10000 (83%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8360/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8356/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8358/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8365/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8390/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8357/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8368/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8360/10000 (84%)\n",
      "Test set: Average loss: 0.0043, Accuracy: 8365/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8356/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8351/10000 (84%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8402/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8375/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8388/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8379/10000 (84%)\n",
      "Test set: Average loss: 0.0043, Accuracy: 8355/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8364/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8373/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8351/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8377/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8377/10000 (84%)\n",
      "Test set: Average loss: 0.0043, Accuracy: 8381/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8391/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8398/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8380/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8382/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8376/10000 (84%)\n",
      "Test set: Average loss: 0.0043, Accuracy: 8374/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8378/10000 (84%)\n",
      "Test set: Average loss: 0.0043, Accuracy: 8398/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8382/10000 (84%)\n",
      "Test set: Average loss: 0.0043, Accuracy: 8380/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8394/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8385/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8378/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8391/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8406/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8405/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8380/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8402/10000 (84%)\n",
      "Test set: Average loss: 0.0043, Accuracy: 8406/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8397/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8393/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8404/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8416/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8386/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8398/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8392/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8399/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8404/10000 (84%)\n",
      "Test set: Average loss: 0.0043, Accuracy: 8401/10000 (84%)\n",
      "Test set: Average loss: 0.0043, Accuracy: 8412/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8390/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8405/10000 (84%)\n",
      "Test set: Average loss: 0.0043, Accuracy: 8392/10000 (84%)\n",
      "Test set: Average loss: 0.0043, Accuracy: 8420/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8433/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8405/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8432/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8425/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8410/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8425/10000 (84%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8434/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8427/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8409/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8420/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8427/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8429/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8399/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8432/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8422/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8441/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8430/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8445/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8409/10000 (84%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8447/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8452/10000 (85%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8436/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8432/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8431/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8432/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8448/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8451/10000 (85%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8422/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8452/10000 (85%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8435/10000 (84%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8452/10000 (85%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8441/10000 (84%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8439/10000 (84%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8446/10000 (84%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8447/10000 (84%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8461/10000 (85%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8464/10000 (85%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8440/10000 (84%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8455/10000 (85%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8471/10000 (85%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8455/10000 (85%)\n",
      "Test set: Average loss: 0.0042, Accuracy: 8453/10000 (85%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8461/10000 (85%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8470/10000 (85%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8477/10000 (85%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8441/10000 (84%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8452/10000 (85%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8468/10000 (85%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8458/10000 (85%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8446/10000 (84%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8466/10000 (85%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8447/10000 (84%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8468/10000 (85%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8478/10000 (85%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8480/10000 (85%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8467/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8487/10000 (85%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8452/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8479/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8469/10000 (85%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8480/10000 (85%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8467/10000 (85%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8469/10000 (85%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8460/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8492/10000 (85%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8464/10000 (85%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8468/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8495/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8465/10000 (85%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8476/10000 (85%)\n",
      "Test set: Average loss: 0.0041, Accuracy: 8475/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8471/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8491/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8471/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8479/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8496/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8472/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8479/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8480/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8480/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8483/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8489/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8484/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8488/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8510/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8500/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8471/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8479/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8489/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8488/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8476/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8506/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8498/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8484/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8496/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8489/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8478/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8488/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8497/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8507/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8503/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8496/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8502/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8508/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8493/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8507/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8523/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8503/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8490/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8508/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8500/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8500/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8477/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8503/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8506/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8519/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8499/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8507/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8534/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8510/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8521/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8506/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8519/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8517/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8513/10000 (85%)\n",
      "Test set: Average loss: 0.0040, Accuracy: 8519/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8517/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8535/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8527/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8511/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8505/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8516/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8524/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8515/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8539/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8538/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8526/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8522/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8525/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8500/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8514/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8527/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8527/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8528/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8532/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8534/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8537/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8533/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8512/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8532/10000 (85%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8531/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8523/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8535/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8524/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8542/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8537/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8551/10000 (86%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8525/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8515/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8515/10000 (85%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8554/10000 (86%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8525/10000 (85%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8541/10000 (85%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8533/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8548/10000 (85%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8528/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8522/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8548/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8541/10000 (85%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8541/10000 (85%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8556/10000 (86%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8534/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8525/10000 (85%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8539/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8525/10000 (85%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8558/10000 (86%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8511/10000 (85%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8561/10000 (86%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8545/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8538/10000 (85%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8543/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8548/10000 (85%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8555/10000 (86%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8564/10000 (86%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8539/10000 (85%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8559/10000 (86%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8561/10000 (86%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8542/10000 (85%)\n",
      "Test set: Average loss: 0.0039, Accuracy: 8552/10000 (86%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8556/10000 (86%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8554/10000 (86%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8565/10000 (86%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8566/10000 (86%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8550/10000 (86%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8556/10000 (86%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8560/10000 (86%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8563/10000 (86%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8541/10000 (85%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8543/10000 (85%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8550/10000 (86%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8554/10000 (86%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8551/10000 (86%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8539/10000 (85%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8563/10000 (86%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8534/10000 (85%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8548/10000 (85%)\n",
      "Test set: Average loss: 0.0037, Accuracy: 8570/10000 (86%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8576/10000 (86%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8538/10000 (85%)\n",
      "Test set: Average loss: 0.0037, Accuracy: 8556/10000 (86%)\n",
      "Test set: Average loss: 0.0037, Accuracy: 8554/10000 (86%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8553/10000 (86%)\n",
      "Test set: Average loss: 0.0037, Accuracy: 8564/10000 (86%)\n",
      "Test set: Average loss: 0.0037, Accuracy: 8566/10000 (86%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8549/10000 (85%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8539/10000 (85%)\n",
      "Test set: Average loss: 0.0037, Accuracy: 8581/10000 (86%)\n",
      "Test set: Average loss: 0.0037, Accuracy: 8567/10000 (86%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8543/10000 (85%)\n",
      "Test set: Average loss: 0.0037, Accuracy: 8566/10000 (86%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8558/10000 (86%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8554/10000 (86%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8533/10000 (85%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8585/10000 (86%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8548/10000 (85%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8548/10000 (85%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8541/10000 (85%)\n",
      "Test set: Average loss: 0.0037, Accuracy: 8568/10000 (86%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8562/10000 (86%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8560/10000 (86%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8548/10000 (85%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8556/10000 (86%)\n",
      "Test set: Average loss: 0.0037, Accuracy: 8550/10000 (86%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8569/10000 (86%)\n",
      "Test set: Average loss: 0.0037, Accuracy: 8557/10000 (86%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8545/10000 (85%)\n",
      "Test set: Average loss: 0.0037, Accuracy: 8559/10000 (86%)\n",
      "Test set: Average loss: 0.0037, Accuracy: 8552/10000 (86%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8570/10000 (86%)\n",
      "Test set: Average loss: 0.0038, Accuracy: 8538/10000 (85%)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f63b012515c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Lo entrene un ratito y tira a 87% con ruido con desviacion 0.4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m       \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.9/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.9/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-e13959234c4e>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "# Lo entrene un ratito y tira a 87% con ruido con desviacion 0.4\n",
    "for i in range(epochs):\n",
    "  for batch_idx, (data, label) in enumerate(train_loader):\n",
    "      data, label = data.to(dev), label.to(dev)\n",
    "\n",
    "      optim.zero_grad()\n",
    "        \n",
    "      predictions = model(data)\n",
    "      loss = cross_entropy(predictions, label)\n",
    "        \n",
    "      loss.backward()\n",
    "      optim.step()\n",
    "  test(model, valid_loader, cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './checkpoint.pt')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mnist_gans.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
